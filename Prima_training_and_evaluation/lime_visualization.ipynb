{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c35e006",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yiweilyu/.conda/envs/ipynbenv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "import sys,os\n",
    "sys.path.insert(0,os.getcwd())\n",
    "from dataset import RachelDataset, collatevisualhash\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea229d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "datas = json.load(open('fake_data/datajson-prospective.json'))\n",
    "datadict = {}\n",
    "for data in datas:\n",
    "    path = data[0]\n",
    "    h = path.split('/')[-1]\n",
    "    datadict[h] = data\n",
    "# Tools for figuring out the series and head models\n",
    "def getseries(h):\n",
    "    data = datadict[h]\n",
    "    return [r[0] for r in data[1]]\n",
    "    \n",
    "def getheadinfo(configjson,taskname):\n",
    "    infos = json.load(open(configjson))\n",
    "    return infos[taskname]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e7a27ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2D_PC_SAG',\n",
       " 'Lt__Cor',\n",
       " 'T1_AXIAL',\n",
       " 'COR_RFRMT',\n",
       " 'AXIAL__T1',\n",
       " 'DWI_SAG',\n",
       " 'coronal',\n",
       " 'AX_SWI']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find series in a study\n",
    "getseries('BRAIN_FAKE_20752')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf6d8025",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fake_data/prospective_classification/vascular_hemorrhagic_intracranial_hemorrhage.txt',\n",
       " [['2025-fake-data-heads/bestauc_vascular_hemorrhagic_intracranial_hemorrhage.pt',\n",
       "   40]]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getheadinfo('fake_data/prospective-config.json','vascular_hemorrhagic_intracranial_hemorrhage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df3e0dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "series_list = getseries('BRAIN_FAKE_20752')\n",
    "series_list.remove('DWI_SAG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1cfff464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in these settings before running occlusion sensitivity\n",
    "device = 'cuda:0' # the device to compute the model with\n",
    "outjsonname = 'lime_output.json' # the output importance dictionary json name\n",
    "#clipmodelname = 'tempmodelsavesite/scratch/checkpoints712bigvit/154.pt' # the checkpoint for the clip model base to use\n",
    "clipmodelname = 'ckpts/last.pt' # the checkpoint for the clip model base to use\n",
    "taskname = 'vascular_hemorrhagic_intracranial_hemorrhage' # the name of the task\n",
    "headmodelname = '2025-fake-data-heads/bestauc_vascular_hemorrhagic_intracranial_hemorrhage.pt' # the head model. You can choose this from the head config json file\n",
    "classid = 48 # the task id of the head model. You must choose this based on the task and the head config json file\n",
    "datapointhash = 'BRAIN_FAKE_20752' # The hash of the datapoint we want to look at\n",
    "exclude_series = series_list # any series we want to exclude in this analysis\n",
    "#excluse_series = []\n",
    "series_of_interest = 'DWI_SAG' # The series that we want to focus on\n",
    "lime_steps = 1000 # Number of lime steps. The more steps means more accurate lime visualization, but also takes longer\n",
    "\n",
    "\n",
    "# alternative models\n",
    "#clipmodelname = 'tempmodelsavesite/scratch/checkpoints720clip/141.pt' # The head config json file is configs/jsons/prospectivecla.json\n",
    "#clipmodelname = 'tempmodelsavesite/scratch/checkpoints712bigvit/154.pt' # The head config json file is configs/jsons/prospectivecla2.json\n",
    "#headmodelname = 'tempmodelsavesite/87-61-bigvitcont/bestauc_cyst_epidermoid_cyst.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "061f016b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lime import lime_base\n",
    "from scipy import spatial\n",
    "from sklearn.utils.validation import check_random_state\n",
    "import numpy as np\n",
    "\n",
    "class Lime_Explainer:\n",
    "    def __init__(self, kernelfn=None, feature_selection=\"none\", verbose=False):\n",
    "        if kernelfn is None:\n",
    "\n",
    "            def kernelfn(d):\n",
    "                return np.sqrt(np.exp(-(d**2) / 0.25**2))\n",
    "\n",
    "        self.base = lime_base.LimeBase(kernelfn, verbose)\n",
    "        self.fs = feature_selection\n",
    "\n",
    "    def explain_instance(\n",
    "        self, inp, serie_of_interest, classfn, num_samples, seed=0, fracs=1\n",
    "    ):\n",
    "        samples = num_samples\n",
    "        randomstate = check_random_state(seed)\n",
    "        series_ord = inp['serienamestr'].index(serie_of_interest)\n",
    "        lentokens = len(inp['visual'][series_ord])\n",
    "        \n",
    "        masks = (\n",
    "            randomstate.randint(0, fracs + 1, lentokens*samples)\n",
    "            .reshape(samples, lentokens)\n",
    "            .astype(np.float64)\n",
    "        )\n",
    "        masks /= float(fracs)\n",
    "        masks[0] = 1\n",
    "        for i,mask in enumerate(masks):\n",
    "            if np.sum(mask) == 0.0:\n",
    "                masks[i] = 1\n",
    "        # print(samples)\n",
    "        distances = np.zeros(samples)\n",
    "        llabels = np.zeros((samples, 1))\n",
    "        for i in tqdm(range(samples)):\n",
    "            newdata = copy.deepcopy(inp)\n",
    "            tensormask = torch.LongTensor(masks[i])\n",
    "            indices = torch.nonzero(tensormask)[:,0]\n",
    "            newdata['visual'][series_ord] = newdata['visual'][series_ord][indices]\n",
    "            newdata['coordinates'][series_ord] = newdata['coordinates'][series_ord][indices]\n",
    "            llabels[i,0] = classfn([newdata])\n",
    "\n",
    "        ret = self.base.explain_instance_with_data(\n",
    "            masks, llabels, distances, 0, lentokens, feature_selection=self.fs\n",
    "        )\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3c7bc61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GOT TO HERE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:35<00:00, 27.88it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = RachelDataset(datajson='fake_data/datajson-prospective.json',\n",
    "            datarootdir='fake_data/data/',\n",
    "            tokenizer='biomed',\n",
    "            text_max_len=128,\n",
    "            is_train=False,\n",
    "            nosplit=True,\n",
    "            vqvaename = 'FAKE_TOKENIZER',\n",
    "            visualhashonly=True,\n",
    "            percentage = 5,\n",
    "            novisualaug = True,\n",
    "            exclude_series = exclude_series\n",
    "            )\n",
    "\n",
    "datapoint = dataset.find_by_hash(datapointhash)\n",
    "posmaps = datapoint['posmap']\n",
    "\n",
    "clipmodel = torch.load(clipmodelname,map_location=device).module\n",
    "\n",
    "print('GOT TO HERE')\n",
    "patchify = copy.deepcopy(clipmodel.patchifier).cpu()\n",
    "\n",
    "\n",
    "collate = collatevisualhash(patchify, device, puttodevice=True)\n",
    "\n",
    "visualclip = clipmodel.visual_model\n",
    "visualclip.make_no_flashattn()\n",
    "visualclip.patdis = False\n",
    "head = torch.load(headmodelname,map_location=device)\n",
    "\n",
    "explainer = Lime_Explainer()\n",
    "\n",
    "def getlogits(datas):\n",
    "    collated = collate(datas)\n",
    "    with torch.no_grad():\n",
    "        with torch.amp.autocast(device_type='cuda',dtype=torch.float16):\n",
    "            clipout = visualclip(collated,retpool=True).to(device)\n",
    "    finalout = head(clipout)\n",
    "    outval = finalout[:,classid]\n",
    "    return outval\n",
    "\n",
    "limeresult = explainer.explain_instance(datapoint,series_of_interest,getlogits,lime_steps)\n",
    "\n",
    "results = limeresult[1]\n",
    "results.sort()\n",
    "\n",
    "\n",
    "tokenimportancedict = {series_of_interest: {}}\n",
    "posmap = posmaps[datapoint['serienamestr'].index(series_of_interest)]\n",
    "assert len(posmap) == len(results)\n",
    "for j,tok in enumerate(results):\n",
    "    jj,importance = tok\n",
    "    assert jj == j\n",
    "    pos = posmap[j]\n",
    "    tokenimportancedict[series_of_interest][pos.item()] = importance\n",
    "\n",
    "json.dump(tokenimportancedict, open(outjsonname,'w+'),indent=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e952290-1841-4195-8652-0e7522edd52e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4448e64-18cc-4d01-beb3-1f6ed7807d2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e3abe3-2b46-43db-9c9f-07580cf0d667",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daad3815-79aa-4c90-b903-c06505f3cfe1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "firstEnv",
   "language": "python",
   "name": "firstenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
